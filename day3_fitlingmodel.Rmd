---
title: "day3_fitlingmodel"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introducing likelihood functions

In Gadget, a likelihood function is specified by supplying likelihood components within the likelihood
file, which is referred to by the main file. Individual likelihood component scores are summed together 
after being multiplied by weights to form a total likelihood score, and likelihood scores are defined by the type of likelihood component specified. 
Component types define both the kind of data and likelihood function being calculated for that component.
Although we refer to 'likelihood scores' throughout this description, it should be kept in mind that these
are more accurately sums of log likelihoods, so that the objective function used for model fitting attempts to minimize the total likelihood score.


### Incorporating data (Ling case study cont.)
In introducing likelihood components, we will first go through those used within the ling example in detail, but only mention the other types as they follow similar patterns of implementation. To use Rgadget to set up likelihood files, the first consideration that should be made is what data are available that would be useful for creating a likelihood component. These have been provided for you here: in the data_provided folder, you will find catch data (as introduced with the fleets), as well as survey indices, catch distribution, and 'stock' distribution data. Catch distribution include numbers at length as well as numbers at age and length by fleet. Each length- or age-bin has been defined as having the lower bound only inclusive, except that the lower bound of the smallest bin and the upper bound of the largest bin are open-ended to include all values lower or higher, respectively. These numbers are then used within Gadget to form proportions among defined bins, which are compared to the same proportions among the same bins simulated in the model. Stock distribution data are numbers within each stock, which for ling is immature or mature, but could for example be gender-specific stocks. These are similarly used to form proportions within Gadget.

As we saw when incorporating catch data into fleet files (day 2), certain attributes need to be present 
in order for the proper and internally consistent Gadget aggregation files to be created alongside these data files. For catch and stock distribution data, these include area, length, and age aggregations. Even when there is only a single bin, these aggregations need to be specified. For example a single area and a single age group is needed for length distributions, in addition to the length bins. Note that bins need not be evenly distributed across the total length range; instead they are highly flexible and can be specified as any grouping. Therefore the user should be careful to ensure that the definitions make sense and that bins do not overlap. In our example below, we show how to add those necessary attributes, although in reality to do this we also use another R package named 'mfdb' that is aimed at database management and data extraction. This package will be briefly introduced on the last day
of this class but is generally beyond the scope of this course.

```{r likelihood}

library(Rgadget)

#assuming you are beginning in a fresh session; this information should be in an 
#initialization script

base_dir <- 'ling_model'
vers <- c('01-base')
gd <- gadget.variant.dir(sprintf(paste0("%s/",vers),base_dir))

ling.imm <- read.gadget.file(gd, 'lingimm')
ling.mat <- read.gadget.file(gd, 'lingmat')
area_file <- read.gadget.file(gd, 'Modelfiles/area')

minage <- ling.imm[[1]]$minage
maxage <- ling.mat[[1]]$maxage
maxlength <- ling.mat[[1]]$maxlength 
minlength <- ling.imm[[1]]$minlength
dl <- ling.imm[[1]]$dl

create_intervals <-  function (prefix, vect) {
  
    x<-
    structure(vect[1:(length(vect)-1)], names = paste0(prefix, vect[1:(length(vect)-1)])) %>% 
    as.list(.) %>% 
    purrr::map(~structure(., 
                          min = ., 
                          max = vect[-1][which(vect[1:(length(vect)-1)]==.)]))
    
    return(x)
}

create_intervals('len',seq(minlength, maxlength, dl))

#catch distribution data available:
  #length distributions do not regard age bins
ldist.surv <- structure(read_csv('data_provided/ldist_sur.csv'),
            area = list(area_file[[1]]$areas) %>% set_names(.),
            length = create_intervals('len',seq(minlength, maxlength, dl)),
            age = create_intervals('all',seq(minage, maxage, maxage-minage))
            )
ldist.lln <- structure(read_csv('data_provided/ldist_lln.csv'),
            area = list(area_file[[1]]$areas) %>% set_names(.),
            length = create_intervals('len',seq(minlength, maxlength, dl)),
            age = create_intervals('all',seq(minage, maxage, maxage-minage))
            )
ldist.bmt <- structure(read_csv('data_provided/ldist_bmt.csv'),
            area = list(area_file[[1]]$areas) %>% set_names(.),
            length = create_intervals('len',seq(minlength, maxlength, dl)),
            age = create_intervals('all',seq(minage, maxage, maxage-minage))
            )
ldist.gil <- structure(read_csv('data_provided/ldist_gil.csv'),
            area = list(area_file[[1]]$areas) %>% set_names(.),
            length = create_intervals('len',seq(minlength, maxlength, dl)),
            age = create_intervals('all',seq(minage, maxage, maxage-minage))
            )

attributes(ldist.surv)

#age bins needed for age-length distributions
aldist.surv <- structure(read_csv('data_provided/aldist_sur.csv'),
            area = list(area_file[[1]]$areas) %>% set_names(.),
            length = create_intervals('len',seq(minlength, maxlength, dl)),
            age = create_intervals('age',c(minage:11, maxage))
            )
aldist.lln <- structure(read_csv('data_provided/aldist_lln.csv'),
            area = list(area_file[[1]]$areas) %>% set_names(.),
            length = create_intervals('len',seq(minlength, maxlength, dl)),
            age = create_intervals('age',c(minage:11, maxage))
            )
aldist.bmt <- structure(read_csv('data_provided/aldist_bmt.csv'),
            area = list(area_file[[1]]$areas) %>% set_names(.),
            length = create_intervals('len',seq(minlength, maxlength, dl)),
            age = create_intervals('age',c(minage:11, maxage))
            )
aldist.gil <- structure(read_csv('data_provided/aldist_gil.csv'),
            area = list(area_file[[1]]$areas) %>% set_names(.),
            length = create_intervals('len',seq(minlength, maxlength, dl)),
            age = create_intervals('age',c(minage:11, maxage))
            )

attributes(aldist.surv)


#stock distribution data available:
matp.surv <- structure(read_csv('data_provided/matp_sur.csv'),
            area = list(area_file[[1]]$areas) %>% set_names(.),
            length = create_intervals('len',seq(minlength, maxlength, dl*2)),
            age = list(mat_ages = ling.mat[[1]]$minage:ling.mat[[1]]$maxage)
            )

attributes(matp.surv)

```

For ling, length-based indices were used by choosing 7 'slices' of abundance indices across the
length range of ling observed. Index bounds are defined as above, generally inclusive of the lower bound only, but open-ended for the smallest and largest bins.
are all other length- and age- bins presented above). No age extrapolations are necessary. It is important to note that only area and length attributes are included as attributes on these data frames, rather than age as in the distributional components. The length attribute allows `gadget_update` to recognize these data as length-based indices, rather than age-based or acoustic indices, for example. It is also important to keep in mind
here that each slice will have its own estimated catchability per survey (single data frame below)
and area combination (multiple areas may be within a data frame). More on catchability later...

```{r}

#survey index data available: 
slices <- 
  list('len20' = c(20,52), 'len52' = c(52,60), 'len60' = c(60,72), 'len72' = c(72,80), 'len80' = c(80,92), 'len92' = c(92,100), 'len100' = c(100,160) )

# just to illustrate slices:

ldist.surv %>% mutate(length = substring(length, 4) %>% as.numeric) %>% group_by(length) %>% summarise(n = sum(number)) %>% ggplot(aes(x = length, y = n)) + geom_col() + geom_vline(aes(xintercept = length), lty = 2, col = 'orange', data = slices %>% bind_rows() %>% t() %>% .[-1,1] %>% tibble(length = .))
```

```{r}
# set up aggregation info for survey indices
SI1 <- structure(read_csv('data_provided/SI1.csv'),
            area = list(area_file[[1]]$areas) %>% set_names(.),
            length = create_intervals('len', slices[[1]]))
SI2 <- structure(read_csv('data_provided/SI2.csv'),
            area = list(area_file[[1]]$areas) %>% set_names(.),
            length = create_intervals('len', slices[[2]]))
SI3 <- structure(read_csv('data_provided/SI3.csv'),
            area = list(area_file[[1]]$areas) %>% set_names(.),
            length = create_intervals('len', slices[[3]]))
SI4 <- structure(read_csv('data_provided/SI4.csv'),
            area = list(area_file[[1]]$areas) %>% set_names(.),
            length = create_intervals('len', slices[[4]]))
SI5 <- structure(read_csv('data_provided/SI5.csv'),
             area = list(area_file[[1]]$areas) %>% set_names(.),
            length = create_intervals('len', slices[[5]]))
SI6 <- structure(read_csv('data_provided/SI6.csv'),
            area = list(area_file[[1]]$areas) %>% set_names(.),
            length = create_intervals('len', slices[[6]]))
SI7 <- structure(read_csv('data_provided/SI7.csv'),
            area = list(area_file[[1]]$areas) %>% set_names(.),
            length = create_intervals('len', slices[[7]]))

```

Using Rgadget, writing the files that specify the likelihood componenets is straightforward. When calling `gadgetlikilihood`, a likelihood file is created, and a reference to this likelihood file is drawn within the 'main' file. The likelihood file contains a list of likelihood component specifications, and within this list is where the likelihood function, data, and weighting of the likelihood component is specifies. 

Here we start with the distributional components. In all cases, each component receives a distinct name (to be referenced later so keep them short and distinct), weights (1 to yield equal weights for now), data as imported above, and the fleet names and stock names to which these data apply. As a default, Rgadget specifies a sum of squares function to calculate the likelihood score (`'sumofsquares'`), although a variety of other functions are possible, including one for stratified sum of squares (`'stratified'`), multinomial function (`'multinomial'`), pearson function (`'pearson'`), gamma function (`'gamma'`), log function (`'log'`), multivariate normal function (`'mvn'`) or a multivariate logistic function (`'mvlogistic'`). Many of these functions have been tailored for specific data situations (e.g., including tagging or predation data into a likelihood component). More on these functions can be read in the Gadget User Guide. To change the default setting to the stratified sum of squares, for example, one would include an additional argument `function = 'stratified',` to the `gadget_update` call. 

```{r}

lik <-
  gadgetlikelihood('likelihood',gd$dir,missingOkay = TRUE) %>% 
  gadget_update("catchdistribution",
                name = "ldist.surv",
                weight = 1,
                data = ldist.igfs,
                fleetnames = c("surv"),
                stocknames =c("ling.imm","ling.mat")) %>% 
  gadget_update("catchdistribution",
                name = "aldist.surv",
                weight = 1,
                data = aldist.igfs, 
                fleetnames = c("surv"),
                stocknames =c("ling.imm","ling.mat")) %>% 
  gadget_update("catchdistribution",
                name = "ldist.lln",
                weight = 1,
                data = ldist.lln, 
                fleetnames = c("lln"),
                stocknames = c("ling.imm","ling.mat")) %>% 
  gadget_update("catchdistribution",
                name = "aldist.lln",
                weight = 1,
                  data = aldist.lln,
                fleetnames = c("lln"),
                stocknames = c("ling.imm","ling.mat")) %>% 
  gadget_update("catchdistribution",
                name = "ldist.gil",
                weight = 1,
                data = ldist.gil,
                fleetnames = c("gil"),
                stocknames = c("ling.imm","ling.mat")) %>% 
  gadget_update("catchdistribution",
                name = "aldist.gil",
                weight = 1,
                data = aldist.gil,
                fleetnames = c("gil"),
                stocknames = c("ling.imm","ling.mat")) %>% 
  gadget_update("catchdistribution",
                name = "ldist.bmt",
                weight = 1,
                data = ldist.bmt,
                fleetnames = c("bmt"),
                stocknames = c("ling.imm","ling.mat")) %>% 
  gadget_update("catchdistribution",
                name = "aldist.bmt",
                weight = 1,
                data = aldist.bmt,
                fleetnames = c("bmt"),
                stocknames = c("ling.imm","ling.mat")) %>% 
  gadget_update("stockdistribution",
                name = "matp.surv",
                weight = 1,
                  data = matp.surv,
                fleetnames = c("surv"),
                stocknames =c("ling.imm","ling.mat")) 

```

Incorporating survey index components is very similar except that 1) the fact that the survey index is length-based is determined by the length attribute of the data frame, which sets the argument `si_type` to a value of `lengths`, and 2) a catchability function is also specified under the argument `'fittype'`. In addition, the argument `biomass` has a default setting of 0, signifying  a numbers-based index (rather than a biomass-based index, which has a value of 1). Other options for `si_type` can be read about in the Gadget User Guide, and `ages`, `fleets`, `acoustic`, and `effort`.

The catchability function defines the type of linear regression to be used to calculate the likelihood score. Options include a linear fit on the orignal or log scale (`'linearfit'` or `'loglinearfit'`), linear fit with a fixed slope on the original or log scale (`'fixedslopelinearfit'` or `'fixedslopeloglinearfit'`), linear fit with a fixed intercept on the original or log scale (`'fixedinterceptlinearfit'` or `'fixedinterceptlinearfit'`), or a linear/loglinear function with both the slope and intercept fixed (`'fixedlinearfit'` or `'fixedloglinearfit'`). In the first set of cases (linear or loglinear fits), two parameters would be estimated; in the next two sets of cases, only a single parameter is estimated (slope or intercept, whichever is not fixed). In the last set of cases (fixed liner or loglinear fits), no parameters are estimated. Whenever a parameter is fixed, its value needs to be included as an additional argument to `gadget_update`. For example, catchability of the indices of smaller sized fish below are estimated using a log linear fit with both slopes and intercepts estimated, but catchabilities for indices of larger sized fish are calculated using log linear fits with fixed slopes. The slopes are fixed to a value of 1, so the argument '`slope = 1`' is included in the `gadget_update` call.

Notice that, unlike the distributional likelihood components, a fleet is not specified for the survey indices, unless `si_type` is set to `'fleets'`, `'effort'`, `'acoustic'`. Therefore, the suitability curve of a certain fleet is not accounted for when catchabilities are estimated, except when `si_type` is set to `'fleets'` or  `'effort'` . In this latter case, a single catchability is estimated instead of a series of catchabilities, corresponding to each age or length index included. Each survey index is matched to stock size observations at a given time and area; therefore, if there are two length- or age-based survey index series with the same time and area, they can each be incorporated as separate likelihood components as long as they have different names. 

```{r}
lik <-
  lik %>%  
  gadget_update("surveyindices",
                name = paste0("si.", names(slices)[1]),
                weight = 1,
                data = SI1,
                fittype = 'loglinearfit',
                stocknames = c("ling.imm","ling.mat")) %>% 
  gadget_update("surveyindices",
                name = paste0("si.", names(slices)[2]),
                weight = 1,
                data = SI2,
                fittype = 'loglinearfit',
                stocknames = c("ling.imm","ling.mat")) %>% 
  gadget_update("surveyindices",
                name = paste0("si.", names(slices)[3]),
                weight = 1,
                data = SI3,
                fittype = 'fixedslopeloglinearfit',
                slope=1,
                stocknames = c("ling.imm","ling.mat")) %>% 
  gadget_update("surveyindices",
                name = paste0("si.", names(slices)[4]),
                weight = 1,
                data = SI4,
                fittype = 'fixedslopeloglinearfit',
                slope=1,
                stocknames = c("ling.imm","ling.mat")) %>% 
  gadget_update("surveyindices",
                name = paste0("si.", names(slices)[5]),
                weight = 1,
                data = SI5,
                fittype = 'fixedslopeloglinearfit',
                slope=1,
                stocknames = c("ling.imm","ling.mat")) %>% 
  gadget_update("surveyindices",
                name = paste0("si.", names(slices)[6]),
                weight = 1,
                data = SI6,
                fittype = 'fixedslopeloglinearfit',
                slope=1,
                stocknames = c("ling.imm","ling.mat")) %>% 
  gadget_update("surveyindices",
                name = paste0("si.", names(slices)[7]),
                weight = 1,
                data = SI7,
                fittype = 'fixedslopeloglinearfit',
                slope=1,
                stocknames = c("ling.imm","ling.mat")) 
  
```

Finally, there are two components to the likelihood that do not incorporate data but are instead used to ensure that the optimisation search algorithm remains within reasonable ranges of the objective function. The first component provides penalties for exceeding parameter bounds as set by the user in the input parameter file. In this case, the weight is set to 0.5, but see the troubleshooting page for cases in which it may be wise to set this weight higher. The data frame provided to this likelihood component specifies the power and parameter weights supplied if the parameter value exceeds its upper and lower bounds. In this case, if the likelihood of a parameter exceeds either the upper or lower bound, the distance between the bound and the parameter value is squared and multiplied by the parameter weights 10000; then the sum of these scores across all parameters is multiplied by the 0.5 weighting before being summed along with the other likelihood components to form the total. 

Understocking introduces a penalty when there are insufficent prey to met the requiremtnes of the predators. For example, if landings of the fleets exceeds available biomass, then the penalty is applied. The understocking penalty likelihood is then defined as the sum of the number of prey that are 'missing', raised to a power set by default to 2, and multiplied by the likelihood weight of 100 as indicated below.

```{t}
  lik <-
  lik %>% 
  gadget_update("penalty",
                name = "bounds",
                weight = "0.5",
                data = data.frame(
                  switch = c("default"),
                  power = c(2),
                  upperW=10000,
                  lowerW=10000,
                  stringsAsFactors = FALSE)) %>%
  gadget_update("understocking",
                name = "understocking",
                weight = "100") %>% 
  write.gadget.file(gd)

```

Notice that when the likelihood file is written, so are all the supporting aggregation files under the
'Aggfiles' folder.

## Set optimisation function parameters and fit Gadget statistical model

## Visualize Gadget statistical model fit


